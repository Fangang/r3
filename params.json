{"tagline":"r³ is a map-reduce engine written in python using redis as a backend","body":"r³\r\n==\r\n\r\nr³ is a map reduce engine written in python using a redis backend. It's purpose\r\nis to be simple.\r\n\r\nr³ has only three concepts to grasp: input streams, mappers and reducers.\r\n\r\nThe diagram below relates how they interact:\r\n\r\n![r³ components interaction](https://github.com/heynemann/r3/raw/master/r3.png)\r\n\r\nIf the diagram above is a little too much to grasp right now, don't worry. Keep\r\nreading and use this diagram later for reference.\r\n\r\nA fairly simple map-reduce example to solve is counting the number of\r\noccurrences of each word in an extensive document. We'll use this scenario as\r\nour example.\r\n\r\nInstalling\r\n----------\r\n\r\nInstalling r³ is as easy as:\r\n\r\n    pip install r3\r\n\r\nAfter successful installation, you'll have three new commands: `r3-app`,\r\n`r3-map` and `r3-web`.\r\n\r\nRunning the App\r\n---------------\r\n\r\nIn order to use r³ you must have a redis database running. Getting one up in\r\nyour system is beyond the scope of this document.\r\n\r\nWe'll assume you have one running at 127.0.0.1, port 7778 and configured to\r\nrequire the password 'r3' using database 0.\r\n\r\nThe service that is at the heart of r³ is `r3-app`. It is the web-server that\r\nwill receive requests for map-reduce jobs and return the results.\r\n\r\nTo run `r3-app`, given the above redis back-end, type:\r\n\r\n    r3-app --redis-port=7778 --redis-pass=r3 -c config.py\r\n\r\nWe'll learn more about the configuration file below.\r\n\r\nGiven that you have a proper configuration file, your r3 service will be\r\navailable at `http://localhost:8888`.\r\n\r\nAs to how we actually perform a map-reduce operation, we'll see that after the\r\n`Running Mappers` section.\r\n\r\nApp Configuration\r\n-----------------\r\n\r\nIn the above section we specified a file called `config.py` as configuration.\r\nNow we'll see what that file contains.\r\n\r\nThe configuration file that we pass to the `r3-app` command is responsible for\r\nspecifying `input stream processors` and `reducers` that should be enabled.\r\n\r\nLet's see a sample configuration file:\r\n\r\n    INPUT_STREAMS = [\r\n        'test.count_words_stream.CountWordsStream'\r\n    ]\r\n\r\n    REDUCERS = [\r\n        'test.count_words_reducer.CountWordsReducer'\r\n    ]\r\n\r\nThis configuration specifies that there should be a `CountWordsStream` input\r\nstream processor and a `CountWordsReducer` reducer. Both will be used by the\r\n`stream` service to perform a map-reduce operation. \r\n\r\nWe'll learn more about `input streams` and `reducers` in the sections below.\r\n\r\nThe input stream\r\n----------------\r\n\r\nThe input stream processor is the class responsible for creating the input\r\nstreams upon which the mapping will occur.\r\n\r\nIn our counting words in a document sample, the input stream processor class\r\nshould open the document, read the lines in the document and then return each\r\nline to `r3-app`.\r\n\r\nLet's see a possible implementation:\r\n\r\n    from os.path import abspath, dirname, join\r\n\r\n    class CountWordsStream:\r\n        job_type = 'count-words'\r\n        group_size = 1000\r\n\r\n        def process(self, app, arguments):\r\n            with open(abspath(join(dirname(__file__), 'chekhov.txt'))) as f:\r\n                contents = f.readlines()\r\n\r\n            return [line.lower() for line in contents]\r\n\r\nThe `job_type` property is required and specifies the relationship that this\r\ninput stream has with mappers and with a specific reducer.\r\n\r\nThe `group_size` property specifies how big is an input stream. In the above\r\nexample, our input stream processor returns all the lines in the document, but\r\nr³ will group the resulting lines in batches of 1000 lines to be processed by\r\neach mapper. How big is your group size varies wildly depending on what your\r\nmapping consists of.\r\n\r\nRunning Mappers\r\n---------------\r\n\r\n`Input stream processors` and `reducers` are sequential and thus run in-process\r\nin the r³ app. Mappers, on the other hand, are inherently parallel and are run\r\non their own as independent worker units.\r\n\r\nConsidering the above example of input stream and reducer, we'll use a\r\n`CountWordsMapper` class to run our mapper.\r\n\r\nWe can easily start the mapper with:\r\n\r\n    r3-map --redis-port=7778 --redis-pass=r3 --mapper-key=mapper-1 --mapper-class=\"test.count_words_mapper.CountWordsMapper\"\r\n\r\nThe `redis-port` and `redis-pass` arguments require no further explanation.\r\n\r\nThe `mapper-key` argument specifies a unique key for this mapper. This key \r\nshould be the same once this mapper restarts.\r\n\r\nThe `mapper-class` is the class r³ will use to map input streams.\r\n\r\nLet's see what this map class looks like. If we are mapping lines (what we got\r\nout of the input stream steap), we should return each word and how many times\r\nit occurs.\r\n\r\n    from r3.worker.mapper import Mapper\r\n\r\n    class CountWordsMapper(Mapper):\r\n        job_type = 'count-words'\r\n\r\n        def map(self, lines):\r\n            return list(self.split_words(lines))\r\n\r\n        def split_words(self, lines):\r\n            for line in lines:\r\n                for word in line.split():\r\n                    yield word, 1\r\n\r\nThe `job_type` property is required and specifies the relationship that this\r\nmapper has with a specific input stream and with a specific reducer.\r\n\r\nReducing\r\n--------\r\n\r\nAfter all input streams have been mapped, it is time to reduce our data to one\r\ncoherent value. This is what the reducer does.\r\n\r\nIn the case of counting word occurrences, a sample implementation is as\r\nfollows:\r\n\r\n    from collections import defaultdict\r\n\r\n    class CountWordsReducer:\r\n        job_type = 'count-words'\r\n\r\n        def reduce(self, app, items):\r\n            word_freq = defaultdict(int)\r\n            for line in items:\r\n                for word, frequency in line:\r\n                    word_freq[word] += frequency\r\n\r\n            return word_freq\r\n\r\nThe `job_type` property is required and specifies the relationship that this\r\nreducer has with mappers and with a specific input stream.\r\n\r\nThis reducer will return a dictionary that contains all the words and the\r\nfrequency with which they occur in the given file.\r\n\r\nTesting our Solution\r\n-------------------\r\n\r\nTo test the above solution, just clone r³'s repository and run the commands\r\nfrom the directory you just cloned.\r\n\r\nGiven that we have the above working, we should have `r3-app` running at\r\n`http://localhost:8888`. In order to access our `count-words` job we'll point\r\nour browser to:\r\n\r\n    http://localhost:8888/count-words\r\n\r\nThis should return a JSON document with the resulting occurrences of words in\r\nthe sample document.\r\n\r\nCreating my own Reducers\r\n------------------------\r\n\r\nAs you have probably guessed, creating new jobs of mapping and reducing is as\r\nsimple as implementing your own `input stream processor`, `mapper` and\r\n`reducer`.\r\n\r\nAfter they are implemented, just include the processor and reducer in the\r\nconfig file and fire up as many mappers as you want.\r\n\r\nMonitoring r³\r\n-------------\r\n\r\nWe talked about three available commands: `r3-app`, `r3-map` and `r3-web`.\r\n\r\nThe last one fires up a monitoring interface that helps you in understanding\r\nhow your r³ farm is working.\r\n\r\nSome screenshots of the monitoring application:\r\n\r\n![r³ web monitoring interface](https://github.com/heynemann/r3/raw/master/r3-web-1.jpg)\r\n\r\nFailed jobs monitoring:\r\n\r\n![r³ web monitoring interface](https://github.com/heynemann/r3/raw/master/r3-web-2.jpg)\r\n\r\nStats:\r\n\r\n![r³ web monitoring interface](https://github.com/heynemann/r3/raw/master/r3-web-3.jpg)\r\n\r\n","google":"UA-33460934-1","name":"R3","note":"Don't delete this file! It's used internally to help with page regeneration."}